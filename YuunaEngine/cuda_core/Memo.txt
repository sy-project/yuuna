NVidia 제품 확인 후 아닐 경우 unload 나 return 필요.

기본적인 연산은 cpu, 사운드 트레이싱 혹은 그와 비슷한 모든 병렬적인 연산이 필요할 경우 cuda
cuda > 터레인(빌보드 알고리즘), 레이트레이싱

Cuda Memo
To be cpu > gpu
1. use cudaError_t func
2. in cudaError_t func, malloc to gpu
3. in cudaError_t func, call __global__ func
(optional) 4. in __global__, can use __device__ func

변수 종류
{
     __global__ -> 함수 선언문 앞에 쓸 경우 그 함수가 쿠다함수라고 지정을 해준다. 사용할함수명<<<블록 갯수, 쓰레드 갯수>>>(변수)
     __device__ -> global과 마찬가지로 gpu에서 실행한다. 하지만 host에서 호출이 안되고, 쿠다함수 내에서만 가능하다. 재귀호출X
                  변수 수식어로 쓸 경우, 글로벌 메모리 영역에 할당되어서 프로그램이 종료될 때 까지 유효한다. 모든 쓰레드가 접근 가능.
                  함수 내에서 선언이 불가능하다.
                  host에서는 쿠다 API함수를 통해 읽기쓰기 가능. 하지만 CUDA5.0부터는 "" 로 감싸주어야한다.
     __host__ -> 우리가 기존에 알고있던 함수처럼 cpu에서 실행하지만, 쿠다 함수 내에서는 호출이 안된다.
     __device__ __host__ -> cpu와 gpu에서 동시에 호출할 수 있는 함수로 쓸 수 있다. 아마 매크로 함수로 자주 쓰일거같다.
     __constant__ -> 변수 수식어로, 프로그램이 종료될 때까지 유효하고 모든 쓰레드에서 접근이 가능하지만, 읽기만 가능하다.
                     대신 host에서 cudaMemcpyToSymbol 함수를 통해 값을 쓰기가 가능하다.
                     CUDA5.0부터는 사용이 어렵다.
     __shared__ -> 공유 메모리 영역에 할당됩니다. 실행중인 쓰레드 블록상에서만 유효.
                   같은 블록 안에있을 경우 접근하여 읽기가능.
                   같은 블록 내에선 첫 쓰레드에 쓰인 값을 받아온 후 쓰기 불가.
                   첫 쓰레드에서만 쓰기 가능.
     dim3 -> 쿠다 함수에서 실행할 쓰레드와 블록의 3차원 배열을 지정하는데에 도움을 주는 변수이다.
             dim3 a(x,y,z) x y z 지정이 없으면 1로 지정된다.
     cudaError_t -> 에러 종류 받아오기. 만약 cudaSuccess 일 경우엔 제대로 일을 한것.
     blockIdx -> 현재 블록의 위치를 알 수 있다. 블록이란, 쓰레드들이 모인 집합. 3차원 배열로 x, y, z 모두 가능.
     threadIdx -> 현재 쓰레드의 위치를 알 수 있다. 3차원 배열로 x, y, z 모두 가능.
     blockDim -> 현재 블록의 쓰레드 할당 갯수를 알 수 있다. 3차원 배열로 x, y, z 모두 가능.
}

1. 쿠다 안에서는 디버그 포인터 적용X
 > Nsight를 이용

2. 쿠다 명령을 for문으로 여러번 실행하는건 속도가 차이가 없음.
   for문과 같은 반복문이 필요한 경우 쿠다 함수 내에서.

3. 쿠다 함수 내에선 cudaMalloc((void**)&변수, 사이즈 * sizeof(사이즈의 변수형))으로 메모리 자리를 먼저 만들어준 후
   cudaMemcpy(디바이스 변수, 호스트 변수, 사이즈 * sizeof(사이즈의 변수형), cudaMemcpyHostToDevice)로 메모리를 복사해준다.

4. 복사해줄때 cudaMemcpyHostToDevice로는 cpu(host)에서 gpu(device)로
   cudaMemcpyDeviceToHost로는 gpu(device)에서 cpu(host)로 데이터를 복사할 수 있다.

5. 쿠다에서 디버그 포인터가 작동을 안하기에 cudaGetLastError()로 놓친 에러를 잡을 수 있다.

6. 쿠다 함수 내에서 선언된 포인터 변수는 다 쓴 후엔 cudaFree(변수)로 메모리를 해제시켜줘야한다.

7. 마지막으론 cudaDeviceReset() 함수를 이용해 초기화해준다.

8. 쿠다 함수 안에서 작동되는 코드는 쓰레드는 순차적으로 0부터 증가하지만, 블록은 랜덤이다.

9. 같은 블록 내에선 메모리를 공유한다? 라는듯하다.

10. 한개의 블록은 최대 512개의 쓰레드를 가질 수 있다.

11. 블록은 65535 * 65535 개의 블록을 가질 수 있다.

12. 쓰레드는 16개 단위로 넘게 쓸 경우 if와 %연산으로 쓰레드를 나누면 연산이 느려진다.
 > 넘게 써도 %로 쓰레드를 나누지 않는다면 느려지지않는다.

13. 쿠다 내 함수 이용시 매개변수로 input/output데이터는 포인터로만 값 적용.
 > 리턴값은 void이기때문

14. w는 width, h는 height로 윈도우 창 크기에 따라 block과 grid 사이즈를 자동 조절
    dim3 blockSize(16, 16);
    dim3 gridSize((w + 15) / 16, (h + 15) / 16);